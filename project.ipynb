{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "b45b938fc7420206c5fa3f040f896f2a578fd1045d763cf82b4c02f8772d2aee"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n\n<h1 align=\"center\"><font size=\"5\">Final Project: Classification with Python</font></h1>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Table of Contents</h2>\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ul>\n    <li><a href=\"https://#Section_1\">Instructions</a></li>\n    <li><a href=\"https://#Section_2\">About the Data</a></li>\n    <li><a href=\"https://#Section_3\">Importing Data </a></li>\n    <li><a href=\"https://#Section_4\">Data Preprocessing</a> </li>\n    <li><a href=\"https://#Section_5\">One Hot Encoding </a></li>\n    <li><a href=\"https://#Section_6\">Train and Test Data Split </a></li>\n    <li><a href=\"https://#Section_7\">Train Logistic Regression, KNN, Decision Tree, SVM, and Linear Regression models and return their appropriate accuracy scores</a></li>\n</a></li>\n</div>\n<p>Estimated Time Needed: <strong>180 min</strong></p>\n</div>\n\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Instructions\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In this notebook, you will  practice all the classification algorithms that we have learned in this course.\n\n\nBelow, is where we are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using evaluation metrics learned in the course.\n\nWe will use some of the algorithms taught in the course, specifically:\n\n1. Linear Regression\n2. KNN\n3. Decision Trees\n4. Logistic Regression\n5. SVM\n\nWe will evaluate our models using:\n\n1.  Accuracy Score\n2.  Jaccard Index\n3.  F1-Score\n4.  LogLoss\n5.  Mean Absolute Error\n6.  Mean Squared Error\n7.  R2-Score\n\nFinally, you will use your models to generate the report at the end. \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# About The Dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n\nThe dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n\n| Field         | Description                                           | Unit            | Type   |\n| ------------- | ----------------------------------------------------- | --------------- | ------ |\n| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n| Location      | Location of the Observation                           | Location        | object |\n| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n| RainToday     | If there was rain today                               | Yes/No          | object |\n| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n\nColumn definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## **Import the required libraries**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import jaccard_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport sklearn.metrics as metrics",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "### Importing the Dataset\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "await download(path, \"Weather_Data.csv\")\nfilename =\"Weather_Data.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"Weather_Data.csv\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "> Note: This version of the lab is designed for JupyterLite, which necessitates downloading the dataset to the interface. However, when working with the downloaded version of this notebook on your local machines (Jupyter Anaconda), you can simply **skip the steps above of \"Importing the Dataset\"** and use the URL directly in the `pandas.read_csv()` function. You can uncomment and run the statements in the cell below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#filepath = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv\"\n#df = pd.read_csv(filepath)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "df.head()",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n\n   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n0             41          S        SSW  ...           92           84   \n1             41          W          E  ...           83           73   \n2             41        ESE        ESE  ...           88           86   \n3             41        NNE          E  ...           83           90   \n4             41        NNE          W  ...           88           74   \n\n   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n\n   RainTomorrow  \n0           Yes  \n1           Yes  \n2           Yes  \n3           Yes  \n4           Yes  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2/1/2008</td>\n      <td>19.5</td>\n      <td>22.4</td>\n      <td>15.6</td>\n      <td>6.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>S</td>\n      <td>SSW</td>\n      <td>...</td>\n      <td>92</td>\n      <td>84</td>\n      <td>1017.6</td>\n      <td>1017.4</td>\n      <td>8</td>\n      <td>8</td>\n      <td>20.7</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2/2/2008</td>\n      <td>19.5</td>\n      <td>25.6</td>\n      <td>6.0</td>\n      <td>3.4</td>\n      <td>2.7</td>\n      <td>W</td>\n      <td>41</td>\n      <td>W</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>73</td>\n      <td>1017.9</td>\n      <td>1016.4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>22.4</td>\n      <td>24.8</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2/3/2008</td>\n      <td>21.6</td>\n      <td>24.5</td>\n      <td>6.6</td>\n      <td>2.4</td>\n      <td>0.1</td>\n      <td>W</td>\n      <td>41</td>\n      <td>ESE</td>\n      <td>ESE</td>\n      <td>...</td>\n      <td>88</td>\n      <td>86</td>\n      <td>1016.7</td>\n      <td>1015.6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>23.5</td>\n      <td>23.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2/4/2008</td>\n      <td>20.2</td>\n      <td>22.8</td>\n      <td>18.8</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>83</td>\n      <td>90</td>\n      <td>1014.2</td>\n      <td>1011.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>21.4</td>\n      <td>20.9</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2/5/2008</td>\n      <td>19.7</td>\n      <td>25.7</td>\n      <td>77.4</td>\n      <td>4.8</td>\n      <td>0.0</td>\n      <td>W</td>\n      <td>41</td>\n      <td>NNE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>88</td>\n      <td>74</td>\n      <td>1008.3</td>\n      <td>1004.8</td>\n      <td>8</td>\n      <td>8</td>\n      <td>22.5</td>\n      <td>25.5</td>\n      <td>Yes</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "### Data Preprocessing\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### One Hot Encoding\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, we need to perform one hot encoding to convert categorical variables to binary variables.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "### Training Data and Test Data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Now, we set our 'features' or x values and our Y or target variable.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed.drop('Date',axis=1,inplace=True)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "df_sydney_processed = df_sydney_processed.astype(float)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\nY = df_sydney_processed['RainTomorrow']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "### Linear Regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, Y_train, Y_test = train_test_split(features, Y, test_size=0.2, random_state=10)\n\n(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((2616, 66), (655, 66), (2616,), (655,))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "LinearReg = LinearRegression()\n\n# Training the model using the training data\nLinearReg.fit(X_train, Y_train)\n\n# Displaying the coefficients and intercept of the trained model\nLinearReg.coef_, LinearReg.intercept_",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(array([-2.36883601e-02,  1.30031554e-02,  7.30154915e-04,  6.49290860e-03,\n        -3.51614515e-02,  4.23841910e-03,  1.82843563e-03,  7.89794445e-04,\n         9.55888360e-04,  8.56007751e-03,  7.70261345e-03, -9.24932344e-03,\n        -8.87528023e-03,  1.00457553e-02,  1.44651992e-02, -3.48325241e-03,\n         1.03190076e+10,  1.03190076e+10, -4.35428535e+09, -4.35428535e+09,\n        -4.35428535e+09, -4.35428535e+09, -4.35428535e+09, -4.35428535e+09,\n        -4.35428535e+09, -4.35428535e+09, -4.35428535e+09, -4.35428535e+09,\n        -4.35428535e+09, -4.35428535e+09, -4.35428535e+09, -4.35428535e+09,\n        -4.35428535e+09, -4.35428535e+09,  4.72755310e+09,  4.72755310e+09,\n         4.72755310e+09,  4.72755310e+09,  4.72755310e+09,  4.72755310e+09,\n         4.72755310e+09,  4.72755310e+09,  4.72755310e+09,  4.72755310e+09,\n         4.72755310e+09,  4.72755310e+09,  4.72755310e+09,  4.72755310e+09,\n         4.72755310e+09,  4.72755310e+09, -1.18315500e+10, -1.18315500e+10,\n        -1.18315500e+10, -1.18315500e+10, -1.18315500e+10, -1.18315500e+10,\n        -1.18315500e+10, -1.18315500e+10, -1.18315500e+10, -1.18315500e+10,\n        -1.18315500e+10, -1.18315500e+10, -1.18315500e+10, -1.18315500e+10,\n        -1.18315500e+10, -1.18315500e+10]),\n 1139274582.2150812)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "predictions = LinearReg.predict(X_test)\n\n# Displaying the first few predictions\npredictions[:5]\npredictions1=predictions",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "markdown",
      "source": "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Calculate metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmae = mean_absolute_error(Y_test, predictions)\nmse = mean_squared_error(Y_test, predictions)\nr2 = r2_score(Y_test, predictions)\n\n# Display the metrics\nprint(\"Mean Absolute Error (MAE):\", mae)\nprint(\"Mean Squared Error (MSE):\", mse)\nprint(\"R-squared (R²):\", r2)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean Absolute Error (MAE): 0.256318933909176\nMean Squared Error (MSE): 0.1157209828234031\nR-squared (R²): 0.4271301272061002\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Create a dictionary with the metrics\nmetrics = {\n    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'R-squared (R²)'],\n    'Value': [mae, mse, r2]\n}\n\n# Convert the dictionary to a DataFrame\nmetrics_df = pd.DataFrame(metrics)\n\n# Display the DataFrame\nprint(metrics_df) ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                      Metric     Value\n0  Mean Absolute Error (MAE)  0.256319\n1   Mean Squared Error (MSE)  0.115721\n2             R-squared (R²)  0.427130\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "### KNN\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\n\n# Creating the KNN model with n_neighbors set to 4\nKNN = KNeighborsClassifier(n_neighbors=4)\n\n# Training the KNN model using the training data\nKNN.fit(X_train, Y_train)\n\n# Displaying the KNN model details\nprint(KNN)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "KNeighborsClassifier(n_neighbors=4)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Using the trained KNN model to make predictions on the test data\npredictions = KNN.predict(X_test)\n\n# Displaying the first few predictions\nprint(predictions[:5])\npredictions2=predictions",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 1. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "markdown",
      "source": "#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Calculate metrics for KNN predictions\nmae_knn = mean_absolute_error(Y_test, predictions)\nmse_knn = mean_squared_error(Y_test, predictions)\nr2_knn = r2_score(Y_test, predictions)\n\n# Display the metrics\nprint(\"KNN Model Metrics:\")\nprint(\"Mean Absolute Error (MAE):\", mae_knn)\nprint(\"Mean Squared Error (MSE):\", mse_knn)\nprint(\"R-squared (R²):\", r2_knn)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "KNN Model Metrics:\nMean Absolute Error (MAE): 0.18167938931297709\nMean Squared Error (MSE): 0.18167938931297709\nR-squared (R²): 0.10060694175205365\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "### Decision Tree\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Creating the Decision Tree model\nTree = DecisionTreeClassifier()\n\n# Training the Decision Tree model using the training data\nTree.fit(X_train, Y_train)\n\n# Displaying the Decision Tree model details\nprint(Tree)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "DecisionTreeClassifier()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "# Using the trained Decision Tree model to make predictions on the test data\npredictions = Tree.predict(X_test)\n\n# Displaying the first few predictions\nprint(predictions[:5])\npredictions3=predictions",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 1. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 43
    },
    {
      "cell_type": "markdown",
      "source": "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Calculate metrics for Decision Tree predictions\nmae_tree = mean_absolute_error(Y_test, predictions)\nmse_tree = mean_squared_error(Y_test, predictions)\nr2_tree = r2_score(Y_test, predictions)\n\n# Display the metrics\nprint(\"Decision Tree Model Metrics:\")\nprint(\"Mean Absolute Error (MAE):\", mae_tree)\nprint(\"Mean Squared Error (MSE):\", mse_tree)\nprint(\"R-squared (R²):\", r2_tree)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Decision Tree Model Metrics:\nMean Absolute Error (MAE): 0.24580152671755726\nMean Squared Error (MSE): 0.24580152671755726\nR-squared (R²): -0.21682590233545684\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": "### Logistic Regression\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Splitting the data with test size of 0.2 and random state 1\nX_train_new, X_test_new, Y_train_new, Y_test_new = train_test_split(features, Y, test_size=0.2, random_state=1)\n\n(X_train_new.shape, X_test_new.shape, Y_train_new.shape, Y_test_new.shape)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((2616, 66), (655, 66), (2616,), (655,))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Creating the Logistic Regression model with solver set to 'liblinear'\nLR = LogisticRegression(solver='liblinear')\n\n# Training the Logistic Regression model using the training data\nLR.fit(X_train_new, Y_train_new)\n\n# Displaying the Logistic Regression model details\nprint(LR)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "LogisticRegression(solver='liblinear')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Using the trained Logistic Regression model to make predictions on the test data\npredictions = LR.predict(X_test_new)\n\n\n# Displaying the first few predictions and predicted probabilities\nprint(\"Predictions:\", predictions[:5])\npredictions4=predictions",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Predictions: [0. 0. 0. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "predict_proba = LR.predict_proba(X_test_new)\nprint(\"Predicted Probabilities:\", predict_proba[:5])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Predicted Probabilities: [[0.73237141 0.26762859]\n [0.97552763 0.02447237]\n [0.53317815 0.46682185]\n [0.85161636 0.14838364]\n [0.96854679 0.03145321]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score\n\n# Making predictions and getting predicted probabilities\npredictions = LR.predict(X_test_new)\npredict_proba = LR.predict_proba(X_test_new)[:, 1]  # Probability for the positive class\n\n# Calculate metrics for Logistic Regression predictions\nmae_lr = mean_absolute_error(Y_test_new, predictions)\nmse_lr = mean_squared_error(Y_test_new, predictions)\nr2_lr = r2_score(Y_test_new, predictions)\nroc_auc_lr = roc_auc_score(Y_test_new, predict_proba)\n\n# Display the metrics\nprint(\"Logistic Regression Model Metrics:\")\nprint(\"Mean Absolute Error (MAE):\", mae_lr)\nprint(\"Mean Squared Error (MSE):\", mse_lr)\nprint(\"R-squared (R²):\", r2_lr)\nprint(\"ROC AUC Score:\", roc_auc_lr)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Logistic Regression Model Metrics:\nMean Absolute Error (MAE): 0.1618320610687023\nMean Squared Error (MSE): 0.1618320610687023\nR-squared (R²): 0.19348093766698415\nROC AUC Score: 0.8813395906419161\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "### SVM\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\n\n# Creating the SVM model\nSVM = SVC()\n\n# Training the SVM model using the training data\nSVM.fit(X_train_new, Y_train_new)\n\n# Displaying the SVM model details\nprint(SVM)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SVC()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "source": "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Enter Your Code and Execute",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Using the trained SVM model to make predictions on the test data\npredictions = SVM.predict(X_test_new)\n\n# Displaying the first few predictions\nprint(predictions[:5])\npredictions5=predictions",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[0. 0. 0. 0. 0.]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "source": "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score\n\n# Calculate metrics for SVM predictions\nmae_svm = mean_absolute_error(Y_test_new, predictions)\nmse_svm = mean_squared_error(Y_test_new, predictions)\nr2_svm = r2_score(Y_test_new, predictions)\n\n# Since SVM might not output probabilities, ROC AUC may not be applicable directly here\n# If you want to calculate the ROC AUC score, you can predict probabilities instead\npredict_proba_svm = SVM.decision_function(X_test_new)  # Use decision_function for SVM\nroc_auc_svm = roc_auc_score(Y_test_new, predict_proba_svm)\n\n# Display the metrics\nprint(\"SVM Model Metrics:\")\nprint(\"Mean Absolute Error (MAE):\", mae_svm)\nprint(\"Mean Squared Error (MSE):\", mse_svm)\nprint(\"R-squared (R²):\", r2_svm)\nprint(\"ROC AUC Score:\", roc_auc_svm)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "SVM Model Metrics:\nMean Absolute Error (MAE): 0.2778625954198473\nMean Squared Error (MSE): 0.2778625954198473\nR-squared (R²): -0.38477801268498935\nROC AUC Score: 0.8609878493599424\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": "### Report\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n\n\\*LogLoss is only for Logistic Regression Model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.metrics import accuracy_score, jaccard_score, f1_score, log_loss\n\n# Assuming you have predictions from each model stored in variables\npredictions_linear = predictions1 # Your Linear Regression predictions\npredictions_knn = predictions2     # Your KNN predictions\npredictions_tree = predictions3   # Your Decision Tree predictions\npredictions_lr = predictions4     # Your Logistic Regression predictions\npredictions_svm = predictions5   # Your SVM predictions\n\npredictions_linear_binary = (predictions_linear >= 0.5).astype(int)\npredictions_lr_binary = (predictions_lr >= 0.5).astype(int)\npredictions_svm_binary = (predictions_svm >= 0.5).astype(int)\n# Calculating metrics for each model\nmetrics = {\n    \"Model\": [\"Linear Regression\", \"KNN\", \"Decision Tree\", \"Logistic Regression\", \"SVM\"],\n    \"Accuracy\": [\n        accuracy_score(Y_test_new, predictions_linear),\n        accuracy_score(Y_test_new, predictions_knn),\n        accuracy_score(Y_test_new, predictions_tree),\n        accuracy_score(Y_test_new, predictions_lr),\n        accuracy_score(Y_test_new, predictions_svm)\n    ],\n    \"Jaccard Index\": [\n        jaccard_score(Y_test_new, predictions_linear),\n        jaccard_score(Y_test_new, predictions_knn),\n        jaccard_score(Y_test_new, predictions_tree),\n        jaccard_score(Y_test_new, predictions_lr),\n        jaccard_score(Y_test_new, predictions_svm)\n    ],\n    \"F1-Score\": [\n        f1_score(Y_test_new, predictions_linear),\n        f1_score(Y_test_new, predictions_knn),\n        f1_score(Y_test_new, predictions_tree),\n        f1_score(Y_test_new, predictions_lr),\n        f1_score(Y_test_new, predictions_svm)\n    ],\n    \"LogLoss\": [\n        log_loss(Y_test_new, LR.predict_proba(X_test_new)[:, 1]),\n        log_loss(Y_test_new, KNN.predict_proba(X_test_new)[:, 1]),\n        log_loss(Y_test_new, Tree.predict_proba(X_test_new)[:, 1]),\n        log_loss(Y_test_new, LR.predict_proba(X_test_new)[:, 1]),\n        log_loss(Y_test_new, SVM.decision_function(X_test_new))\n    ]\n}\n\n# Creating the DataFrame\nmetrics_df = pd.DataFrame(metrics)\n\n# Displaying the metrics DataFrame\nprint(metrics_df)\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ValueError'>",
          "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[48], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m predictions_svm_binary \u001b[38;5;241m=\u001b[39m (predictions_svm \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculating metrics for each model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m---> 18\u001b[0m         \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_linear\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     19\u001b[0m         accuracy_score(Y_test_new, predictions_knn),\n\u001b[1;32m     20\u001b[0m         accuracy_score(Y_test_new, predictions_tree),\n\u001b[1;32m     21\u001b[0m         accuracy_score(Y_test_new, predictions_lr),\n\u001b[1;32m     22\u001b[0m         accuracy_score(Y_test_new, predictions_svm)\n\u001b[1;32m     23\u001b[0m     ],\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJaccard Index\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     25\u001b[0m         jaccard_score(Y_test_new, predictions_linear),\n\u001b[1;32m     26\u001b[0m         jaccard_score(Y_test_new, predictions_knn),\n\u001b[1;32m     27\u001b[0m         jaccard_score(Y_test_new, predictions_tree),\n\u001b[1;32m     28\u001b[0m         jaccard_score(Y_test_new, predictions_lr),\n\u001b[1;32m     29\u001b[0m         jaccard_score(Y_test_new, predictions_svm)\n\u001b[1;32m     30\u001b[0m     ],\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-Score\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     32\u001b[0m         f1_score(Y_test_new, predictions_linear),\n\u001b[1;32m     33\u001b[0m         f1_score(Y_test_new, predictions_knn),\n\u001b[1;32m     34\u001b[0m         f1_score(Y_test_new, predictions_tree),\n\u001b[1;32m     35\u001b[0m         f1_score(Y_test_new, predictions_lr),\n\u001b[1;32m     36\u001b[0m         f1_score(Y_test_new, predictions_svm)\n\u001b[1;32m     37\u001b[0m     ],\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     39\u001b[0m         log_loss(Y_test_new, LR\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_new)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     40\u001b[0m         log_loss(Y_test_new, KNN\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_new)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     41\u001b[0m         log_loss(Y_test_new, Tree\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_new)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     42\u001b[0m         log_loss(Y_test_new, LR\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_new)[:, \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     43\u001b[0m         log_loss(Y_test_new, SVM\u001b[38;5;241m.\u001b[39mdecision_function(X_test_new))\n\u001b[1;32m     44\u001b[0m     ]\n\u001b[1;32m     45\u001b[0m }\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Creating the DataFrame\u001b[39;00m\n\u001b[1;32m     48\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(metrics)\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/sklearn/metrics/_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     96\u001b[0m             type_true, type_pred\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"Section_5\">  How to submit </h2>\n\n<p>Once you complete your notebook you will have to share it. You can download the notebook by navigating to \"File\" and clicking on \"Download\" button.\n\n<p>This will save the (.ipynb) file on your computer. Once saved, you can upload this file in the \"My Submission\" tab, of the \"Peer-graded Assignment\" section.  \n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>About the Authors:</h2> \n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n\n### Other Contributors\n\n[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n\n<!--\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By    | Change Description          |\n| ----------------- | ------- | ------------- | --------------------------- |\n| 2022-06-22        | 2.0     | Svitlana K.   | Deleted GridSearch and Mock |\n--!>",
      "metadata": {}
    }
  ]
}